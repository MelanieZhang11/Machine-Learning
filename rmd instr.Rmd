---
title: "Machine Learning Course Project"
author: "Yida Zhang"
date: "April 11, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project Overview

This project utilized body movement data generated by activity tracking devices to predict whether the device wearer was performing physical exercises correctly. Data from 6 participants were collected in this exercise, and they were asked to perform barbell lifts correctly and incorrectly in 5 different ways (class A, B, C, D and E). Training set consists of 19622 observations with classes determined, whereas testing set consists of 20 observations with unknown classes.

## Methodology

**1. Data importing and cleaning:** training data and testing data was imported to R. 100 Fields with missing values were removed, leaving 59 fields for further testing.

**2. Splitting:** training data was split into a training set and a validation set, for the purpose that different algorithms would be trained using training set and evaluated by the accuracy demonstrated using validation set. The split was set to be 80/20 (training/validation).

**3. Algorithm training:** three different types of algorithms were used in the training process: multinomial logistic regression, random forest, and KNN. 

**4. Predicting:** based on the prediction performance with the validation set, one method would be selected to predict the classes of the testing set


## Model Selection

1. Multinomial Logistic Regression

```{r load, echo=FALSE, include=FALSE}
library(caret)
setwd("C:/Users/rickzhan/Desktop/Meow Meow Meow Mel/R Programming")
load("04102018.RData")
```

```{r m1}
confusionMatrix(predictions2, validation$classe)
```

Multinomial logistic regression algorithm had accuracy of 28.45% with the validation set. The model was a disappointing fit as we can see that it forecasted Class A for every observation in validation set. Despite lackluster effectiveness, multinomial model was relatively efficient to train; training process took approximately 30 min to complete. 

2. Random Forest

```{r m2}
confusionMatrix(predictions, validation$classe)
```

Random forest generated outstanding results with the validation set: 99.97% accuracy. It made only one mistake for one case of Class D by classifying it as E erroneously. Random forecast did took a long time to training, however; training process took about 1.5 hours to complete.

3. KNN

```{r m3}
confusionMatrix(predictions3, validation$classe)
```

KNN was slightly better than Multinomial with a 30% accuracy rate. Unlike multinomial it did make forecasts for every class, but wasn't too effective in doing so especially with Class C. Balanced accuracy for different classes were above 50% but not by a large margin. 

4. Conclusion

Based on the test results on validation set, we will choose Random Forest as the model to predict classes of testing set.

## Further Discussion on Sampling Error

One thing that could potentially improve the robustness of model selection process is to cross-validate multiple times by resampling training set and validation set. The reason why it wasn't done here in this specific project was 1) the large amount time required to train a random forest model, 2) the clear advantage of random forest model demonstrated versus the rest of choices. 

## Prediction on Testing Set

```{r test}
prediction_test
```

Predictions of classes on testing set were submitted at the quiz, and the algorithm hit 100% accuracy with these 20 predictions. 